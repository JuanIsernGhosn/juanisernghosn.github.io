I"ÆL<p>This practice is based on the use of Gaussian processes for the <strong>classification of histological images of the prostate, according to the existence or not of cancer</strong>.</p>

<p>Specifically, this project uses a data set of 1014 images from healthy tissue and 298 from carcinogenic tissue, from which 10 descriptors have been extracted. In this set of data, the folds to be used in cross validation are predetermined, so that the data are first divided according to their class and then each of them in 5 sets of similar size, each representative of a fold of cross validation.</p>

<p>To carry out the classification of the image data, the Gaussian process algorithm will be used, whose functioning will be defined in this report, prior to the presentation of the results obtained through it in the data set. Thus, one of the main challenges of the problem presented here, is the need to achieve the best possible classification through this algorithm, on a set of data that is highly unbalanced. For this reason and for each of the folds of the majority class (negative class) of the cross validation to be performed, we will take all the data of the positive class in order to balance the observations of each class in the models to be trained.</p>

<h2 id="what-is-a-gaussian-process">What is a Gaussian process?</h2>
<p>A Gaussian process consists of a (potentially infinite) collection of random variables, each of which follows a normal distribution, for which given any finite subset of the same, this follows a multivariate normal distribution.</p>

<p>$f(x) ‚àº GP(m(x), k(x,x‚Äô))$</p>

<p>Esta notaci√≥n significa que para cada valor $x ‚àà R^n$, consideramos la funci√≥n $f(x)$ como una variable aleatoria, es decir, se define una distribuci√≥n sobre el conjunto de funciones reales, siendo la funci√≥n de media:</p>

<p>$m(x) := E[f(x)]$</p>

<p>y la funci√≥n de covarianza:</p>

<p>$k(x, x‚Äô) := E[(f(x) ‚àí m(x))(f(x‚Äô) ‚àí m(x‚Äô))]$</p>

<p>Intuitivamente esto significa que el valor de $f(x)$ se trata como una variable aleatoria con media $m(x)$ y con covarianza entre pares de variables aleatorias.</p>

<p>De este modo, un proceso gaussiano define una distribuci√≥n previa, que puede ser convertida en una distribuci√≥n posterior una vez que hayamos visto algunos datos. Aunque pueda parecer dif√≠cil representar una distribuci√≥n sobre una funci√≥n, resulta que s√≥lo necesitamos ser capaces de definirla sobre los valores de la funci√≥n en un conjunto de puntos finitos, pero arbitrarios, por ejemplo $x_{1},‚Ä¶,x_{N}$. Un proceso gaussiano asume que $p(f(x_{1}),‚Ä¶,f(x_{N}))$ sigue de forma conjunta una gaussiana, con media $Œº(x)$ y covarianza $‚àë(x)$ dada por $‚àë<em>{i,j}=k(x</em>{i},x_{j})$, donde $k$ es una funci√≥n de kernel. La idea clave es que si $x_{i}$ y $x_{j}$ el kernel considera que son similares, entonces esperamos que la salida de la funci√≥n en esos puntos sea similar tambi√©n.</p>

<p>As√≠ como para la $Œº(x)$ podemos usar cualquier funci√≥n real, para $k(x_{i},x_{j})$ debe de cumplirse que para cualquier conjunto de elementos, la matriz resultante sea valida para una distribuci√≥n gaussiana multivariable (semidefinitiva positiva), lo cual son las mismas condiciones que para los <em>kernels</em>, por lo que cualquier funci√≥n kernel se puede usar como funci√≥n de covarianza.</p>

<h2 id="software-utilizado-para-la-realizaci√≥n-de-la-pr√°ctica">Software utilizado para la realizaci√≥n de la pr√°ctica</h2>
<p>Para realizar la presente pr√°ctica, se ha hecho uso del lenguaje de programaci√≥n <em>Python</em>, en su versi√≥n 3.7. Del mismo modo, el entorno de desarrollo que se ha utilizado es <em>Pycharm</em>, de la empresa de software JetBrains. Entre los distintos paquetes de Python en los que se implementa el algoritmo de procesos gaussianos, en nuestro caso utilizaremos <strong>GPflow</strong>. GPflow es un paquete para la construcci√≥n de modelos de procesos gaussianos en python, utilizando TensorFlow para ejecutar los c√°lculos, lo que permite una ejecuci√≥n m√°s r√°pida que el resto de paquetes, pues puede hacer uso de GPU.</p>

<p>Para implementar los modelos utilizados en esta pr√°ctica, se ha utilizado el objeto <strong>VGP</strong>, presente en el paquete <em>models</em>. Esta implementaci√≥n del Proceso Gaussiano Variacional (VGP) aproxima la distribuci√≥n posterior a una gaussiana multivariada. Sobre estos modelos VGP, hemos definido la distribuci√≥n de probabilidad que utilizaremos. En nuestro caso, al tratarse de un problema de clasificaci√≥n binaria, haremos uso de una distribuci√≥n de Bernouilli. Por √∫ltimo y de acuerdo a los requisitos formales establecidos para la realizaci√≥n de este trabajo, se hacen uso de dos tipos de kernel distintos para el proceso gaussiano: uno lineal (Linear) y otro gaussiano (RBF), ambos dentro del paquete <em>kernels</em>. Para ambos <em>kernels</em> se ha modificado el tama√±o de la variable <em>input_dim</em> para establecerla al n√∫mero de variables a considerar de nuestro conjunto de datos.</p>

<p>Adem√°s, el resto de paquetes de software que se han utilizado para la implementaci√≥n de esta pr√°ctica han sido:</p>

<ul>
  <li><strong>matplotlib</strong>: Para llevar a cabo las visualizaciones de los gr√°ficos a mostrar en los resultados (Curvas ROC, matrices de confusi√≥n‚Ä¶).</li>
  <li><strong>sklearn</strong>: Tanto para llevar a cabo tareas de preprocesamiento sobre los datos, como para realizar el c√°lculo de m√©tricas para evaluar la clasificaci√≥n efectuada por los modelos generados.</li>
  <li><strong>numpy</strong>: Para efectuar c√°lculos sobre matrices de forma m√°s sencilla y eficiente.</li>
</ul>

<h2 id="resultados-experimentales">Resultados experimentales</h2>
<p>A continuaci√≥n, se muestran los resultados obtenidos para la validaci√≥n cruzada de modelos de procesos gaussianos, en primer lugar con el kernel lineal y posteriormente con el gaussiano.</p>

<h3 id="kernel-lineal">Kernel Lineal</h3>
<p>Una vez realizada la validaci√≥n cruzada sobre el conjunto de datos, haciendo uso de procesos gaussianos con kernel lineal, hemos obtenido una serie de m√©tricas, que a continuaci√≥n se exponen.</p>

<h4 id="curva-roc-y-curva-precisi√≥n-sensibilidad">Curva ROC y curva precisi√≥n-sensibilidad</h4>
<p>Se presenta tanto las curvas ROC obtenidas para cada uno de los modelos generados en los distintas divisiones de los datos en la validaci√≥n cruzada, como las curvas de precisi√≥n y sensibilidad.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Curvas ROC</th>
      <th style="text-align: center">Curvas Precisi√≥n/Sensibilidad</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="Results/Linear_ROC.png" alt="alt text" title="Figura 1: Curvas ROC GP con n√∫cleo lineal" /></td>
      <td style="text-align: center"><img src="Results/Linear_prec_sen.png" alt="alt text" title="Figura 2: Curvas precisi√≥n/sensibilidad GP con n√∫cleo lineal" /></td>
    </tr>
  </tbody>
</table>

<h4 id="matrices-de-confusi√≥n">Matrices de confusi√≥n</h4>
<p>Del mismo modo, a continuaci√≥n se exponen las matrices de confusi√≥n correspondientes a cada uno de los modelos generados en la validaci√≥n cruzada.
<img src="Results/Lineal_CM.png" alt="alt text" title="Figura 3: Matrices de confusi√≥n de la validaci√≥n cruzada de modelos con kernel lineal" /></p>

<h4 id="m√©tricas-por-fold">M√©tricas por fold</h4>
<p>Del mismo modo, se exponen las m√©tricas concretas calculadas a partir de la matriz de confusi√≥n:</p>

<table>
  <thead>
    <tr>
      <th>Fold</th>
      <th>Accuracy</th>
      <th>Specificity</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.719844</td>
      <td>0.645320</td>
      <td>1.000000</td>
      <td>0.428571</td>
      <td>0.600000</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.510638</td>
      <td>0.342857</td>
      <td>1.000000</td>
      <td>0.342857</td>
      <td>0.510638</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.752896</td>
      <td>0.689320</td>
      <td>1.000000</td>
      <td>0.452991</td>
      <td>0.623529</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.804878</td>
      <td>0.765306</td>
      <td>0.960000</td>
      <td>0.510638</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.708955</td>
      <td>0.633166</td>
      <td>0.927536</td>
      <td>0.467153</td>
      <td>0.621359</td>
    </tr>
  </tbody>
</table>

<p>Tabla 1: M√©tricas de clasificaci√≥n para folds de modelos con n√∫cleo lineal</p>

<h4 id="comentario-de-los-resultados-para-kernel-lineal">Comentario de los resultados para kernel lineal</h4>
<p>Tras haber obtenido cada uno de los gr√°ficos y m√©tricas anteriormente expuestos, cabe decir que en t√©rminos generales, el n√∫cleo Lineal tiene un comportamiento un tanto irregular. En primer lugar, se ha de decir que la bondad de la clasificaci√≥n no es siempre buena, tal y como se observan en los resultados anteriores. As√≠, se observa como por ejemplo en el fold 2, la exactitud del clasificador est√° en torno al 50%, con una especificidad cercana al 35%, pero sin embargo con una sensibilidad del 100%. As√≠, en este caso el clasificador parece ser robusto a falsos negativos, penalizando en gran medida los falsos positivos, que en el caso de un problema tan cr√≠tico como el de la detecci√≥n de c√°ncer, resultar√≠a ser una buena caracter√≠stica. Sin embargo, en este fold en concreto, parece como si el modelo no fuera capaz de clasificar la clase negativa. El resto de folds mantienen un comportamiento similar con respecto a la sensibilidad, si bien en el 4 y en el 5 ya se avistan ciertos falsos negativos. Sin embargo, es en la capacidad predictiva de la clase negativa donde el resto de folds tienen un rendimiento mucho mejor que el 2.</p>

<h3 id="kernel-gaussiano">Kernel Gaussiano</h3>
<p>Del mismo modo que se ha hecho para el kernel lineal, se han obtenido una serie de m√©tricas y gr√°ficos sobre los resultados conseguidos con el proceso gaussiano de kernel gaussiano, que a continuaci√≥n se exponen.</p>

<h3 id="curva-roc-y-curva-precisi√≥n-sensibilidad-1">Curva ROC y curva precisi√≥n-sensibilidad</h3>
<p>Curvas ROC                     |  Curvas Precisi√≥n/Sensibilidad
:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì:|:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-:
<img src="Results/Gaussian_ROC.png" alt="alt text" title="Figura 4: Curvas ROC GP con n√∫cleo gaussiano" />  |  <img src="Results/Gaussian_prec_sen.png" alt="alt text" title="Figura5: Curvas precisi√≥n/sensibilidad GP con n√∫cleo gaussiano" /></p>

<h4 id="matrices-de-confusi√≥n-1">Matrices de confusi√≥n</h4>
<p>Del mismo modo, a continuaci√≥n se exponen las matrices de confusi√≥n correspondientes a cada uno de los modelos generados en la validaci√≥n cruzada.
<img src="Results/Gaussian_CM.png" alt="alt text" title="Figura 6: Matrices de confusi√≥n de la validaci√≥n cruzada de modelos con kernel gaussiano" /></p>

<h4 id="m√©tricas-por-fold-1">M√©tricas por fold</h4>
<p>Del mismo modo, se exponen las m√©tricas concretas calculadas a partir de la matriz de confusi√≥n:</p>

<table>
  <thead>
    <tr>
      <th>Fold</th>
      <th>Accuracy</th>
      <th>Specificity</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.871595</td>
      <td>0.916256</td>
      <td>0.703704</td>
      <td>0.690909</td>
      <td>0.697248</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.748227</td>
      <td>0.752381</td>
      <td>0.736111</td>
      <td>0.504762</td>
      <td>0.598870</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.938224</td>
      <td>0.980583</td>
      <td>0.773585</td>
      <td>0.911111</td>
      <td>0.836735</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.894309</td>
      <td>0.903061</td>
      <td>0.860000</td>
      <td>0.693548</td>
      <td>0.767857</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.932836</td>
      <td>0.949749</td>
      <td>0.884058</td>
      <td>0.859155</td>
      <td>0.871429</td>
    </tr>
  </tbody>
</table>

<p>Tabla 2: M√©tricas de clasificaci√≥n para folds de modelos con n√∫cleo gaussiano</p>

<h4 id="comentario-de-los-resultados-para-el-kernel-gaussiano">Comentario de los resultados para el kernel gaussiano</h4>
<p>En t√©rminos generales, estos modelos con n√∫cleo gaussiano clasifican mejor que los obtenidos con n√∫cleo lineal ya que su exactitud (Accuracy) as√≠ lo muestra. Sin embargo, al tratarse de un problema altamente desbalanceado, tenemos que considerar otras medidas que nos dejen entrever la medida en la que nuestro clasificador es √∫til para la resoluci√≥n de nuestro problema. As√≠, podemos observar como la clasificaci√≥n de la clase negativa es en general buena para todos los modelos generados en los distintos folds, siendo la especificidad de los modelos mucho mejor que las obtenidas en los modelos con n√∫cleo lineal. Otro aspecto fundamental en un problema de estas caracter√≠sticas es la sensibilidad de nuestros modelos ya que tal y como se puede apreciar, en estos modelos con n√∫cleo gaussiano, esta baja considerablemente con respecto a los resultados obtenidos con el n√∫cleo lineal. Esto resulta un aspecto significativo y muy negativo, pues sobre sujetos que est√°n enfermos, nuestros clasificadores los dar√≠an como sanos, teniendo en este caso un coste muy elevado la clasificaci√≥n err√≥nea. As√≠ y aunque tanto la especificidad y precisi√≥n de estos modelos resulta mejor que la de los obtenidos con n√∫cleo lineal, la baja sensibilidad nos podr√≠a hacer considerar la opci√≥n de incluso descartar estos modelos.</p>

<h2 id="c√≥mo-se-clasificar√≠a-un-nuevo-dato">¬øC√≥mo se clasificar√≠a un nuevo dato?</h2>
<p>Tras haber entrenado los modelos cuyos resultados se han mostrado anteriormente, nos surge la duda de c√≥mo deber√≠amos clasificar un nuevo dato que llega a nuestro sistema. As√≠, en este ep√≠grafe se propone un procedimiento para llevar a cabo esta tarea, cuyo proceso se describe en las siguientes fases:</p>

<ol>
  <li>En primer lugar, se ha de obtener sobre una imagen nueva, los descriptores del mismo modo que se obtuvieron para los datos de entrenamiento utilizados para entrenar nuestros modelos, de forma que para esta nueva imagen se generen 10 caracter√≠sticas, relativas a cada uno de los descriptores.</li>
  <li>A continuaci√≥n, se ha de llevar a cabo la normalizaci√≥n (centrado y escalado) de este nuevo dato para que pueda ser comparable a los datos con los que se ha entrenado el modelo. Por ello, ha de obtenerse el Z-Score de cada una de las caracter√≠sticas del nuevo dato con la media y desviaci√≥n t√≠pica obtenida para cada una de las variables cuando se realiz√≥ el procedo de normalizado de datos.</li>
  <li>Como los datos ya son comparables con los usados para el entrenamiento, se puede llevar a cabo la clasificaci√≥n del nuevo dato. Para ello y como tras el entrenamiento de los procesos gaussianos resultaron 20 modelos distintos, hemos de buscar un m√©todo para aunar de alg√∫n modo todos y establecer un criterio de selecci√≥n de la clase predicha. Para ello, procedemos del siguiente modo:
    <ol>
      <li>Efectuamos la clasificaci√≥n de nuestro nuevo dato sobre los 20 modelos generados, lo que resulta en un vector de 20 probabilidades respecto a la clasificaci√≥n binaria. Estos datos nos dicen para cada uno de los modelos la probabilidad de que el nuevo dato se corresponda con la clase positiva.</li>
      <li>Sobre esas probabilidades establecemos un threshold, por defecto de 0.5 para poder discernir a partir de qu√© valor de la probabilidad obtenida por cada uno de los modelos, diferenciamos entre la clase positiva y la negativa. Con ello, obtenemos un vector de 20 elementos, teniendo cada uno de estos el valor de la clase que se corresponde con la probabilidad determinada por el respectivo modelo.</li>
      <li>La selecci√≥n de la clase a considerar como la predicha por el sistema se realizar√° eligiendo aquella que m√°s veces aparece en el vector de clases de salida de cada uno de nuestros clasificadores. As√≠, nuestra propuesta de multiclasificador resultar√≠a del consenso o votaci√≥n de los clasificadores procesos gaussianos parciales.</li>
    </ol>
  </li>
</ol>

<h2 id="dise√±o-de-experimento-adicional">Dise√±o de experimento adicional</h2>
<p>En esta pr√°ctica hemos utilizado bagging para balancear las clases. <strong>Tenemos 1014 y 298 ejemplos sanos y cancer√≠genos, respectivamente</strong>. Una duda que se plantea es la b√∫squeda de otra alternativa para aumentar el n√∫mero de ejemplos positivos para balancear los datos. As√≠ en este trabajo adem√°s de la alternativa de bagging, se propone utilizar SMOTE o algunas de las implementaciones similares a este algoritmo, como por ejemplo ADASYN como m√©todo para equilibrar el n√∫mero de muestras de la clase positiva al de clase negativa. As√≠, la responsabilidad del balanceo de las clases pasa del algoritmo de partici√≥n de datos y generaci√≥n de modelos (en nuestro caso bagging), que simula para cada modelo una situaci√≥n de igualdad de datos de cada clase, a ahora residir en el preprocesamiento, que haciendo uso de la distribuci√≥n de los datos observados generar√° otras muestras que se adec√∫en a las mismas caracter√≠sticas.</p>

<p>Es cierto que la generaci√≥n de datos artificiales puede tener inconvenientes, como la poca representatividad de los mismo, haciendo que estos no pertenezcan a la distribuci√≥n que subyace en el dominio de los datos reales. Por ello, una primera alternativa que se tuvo en consideraci√≥n fue llevar a cabo un undersampling, que si bien cumple el requisito fundamental de que las clases de los datos resultantes se encontrar√°n balanceadas, por contra tiene la pega de que se disminuye la cantidad de datos con la que entrenar nuestro modelo, con lo que pueden haber ciertos aspectos del dominio de nuestros datos que no queden cubiertos y nos lleve casi con total seguridad a una peor clasificaci√≥n.</p>

<p>En cuanto a los algoritmos de sampling de datos a utilizar, se propone tanto SMOTE como ADASYN. El funcionamiento de SMOTE es simple. Primero encuentra a los vecinos m√°s cercanos de la clase minoritaria para cada una de las muestras de la clase. Luego dibuja una l√≠nea entre los vecinos y genera puntos aleatorios en dichas l√≠neas. Por su parte ADASYN hace es lo mismo que SMOTE, s√≥lo que con un peque√±o cambio. Despu√©s de crear esa muestra, a√±ade peque√±os valores aleatorios a los puntos, lo que la hace m√°s realista. En otras palabras, en lugar de que toda la muestra est√© linealmente correlacionada con el padre, tienen un poco m√°s de varianza en ellos, es decir, est√°n un poco dispersos.</p>

<p>As√≠, una vez que se tiene el conjunto de datos balanceado deber√≠amos proceder a entrenar nuestro modelo. Para ello realizaremos una validaci√≥n cruzada, por ejemplo de 10-fold. Adicionalmente y si hay par√°metros que se considere que pueden influir de forma positiva en la capacidad predictiva del algoritmo, se puede realizar un Grid de par√°metros, de forma que generar√° sobre cada combinaci√≥n posible de par√°metros una validaci√≥n cruzada, permitiendo observar cual es con la que obtenemos mejores resultados.</p>

<p>Con la combinaci√≥n de par√°metros deseada, se obtendr√° un modelo final, que usar√° como datos de entrenamiento la totalidad del conjunto de datos, de forma que este modelo podr√° usarse para la clasificaci√≥n de datos de nuevas im√°genes que nos lleguen.</p>
:ET