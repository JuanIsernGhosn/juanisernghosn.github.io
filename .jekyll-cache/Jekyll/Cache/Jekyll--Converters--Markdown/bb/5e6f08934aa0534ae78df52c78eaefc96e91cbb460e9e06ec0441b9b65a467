I"¥K<p>This practice is based on the use of Gaussian processes for the <strong>classification of histological images of the prostate, according to the existence or not of cancer</strong>.</p>

<p>Specifically, this project uses a data set of 1014 images from healthy tissue and 298 from carcinogenic tissue, from which 10 descriptors have been extracted. In this set of data, the folds to be used in cross validation are predetermined, so that the data are first divided according to their class and then each of them in 5 sets of similar size, each representative of a fold of cross validation.</p>

<p>To carry out the classification of the image data, the Gaussian process algorithm will be used, whose functioning will be defined in this report, prior to the presentation of the results obtained through it in the data set. Thus, one of the main challenges of the problem presented here, is the need to achieve the best possible classification through this algorithm, on a set of data that is highly unbalanced. For this reason and for each of the folds of the majority class (negative class) of the cross validation to be performed, we will take all the data of the positive class in order to balance the observations of each class in the models to be trained.</p>

<h2 id="what-is-a-gaussian-process">What is a Gaussian process?</h2>
<p>A Gaussian process consists of a (potentially infinite) collection of random variables, each of which follows a normal distribution, for which given any finite subset of the same, this follows a multivariate normal distribution.</p>

<script type="math/tex; mode=display">f(x) ‚àº GP(m(x), k(x,x'))</script>

<p>This notation means that for each value <script type="math/tex">x ‚àà R^n</script>, we consider the function <script type="math/tex">f(x)</script> as a random variable, that is to say, a distribution is defined on the set of real functions, being the function of average:</p>

<script type="math/tex; mode=display">m(x) := E[f(x)]</script>

<p>and the covariance function:</p>

<script type="math/tex; mode=display">k(x, x') := E[(f(x) ‚àí m(x))(f(x') ‚àí m(x'))]</script>

<p>Intuitively this means that the value of <script type="math/tex">f(x)</script> is treated as a random variable with an average of <script type="math/tex">m(x)</script> and a covariance between pairs of random variables.</p>

<p>Thus, a Gaussian process defines a previous distribution, which can be converted to a later distribution once we have seen some data. Although it may seem difficult to represent a distribution over a function, it turns out that we just need to be able to define it over the function values in a set of finite points, but arbitrary, for example <script type="math/tex">x_{1},...,x_{N}</script>. A Gaussian process assumes that <script type="math/tex">p(f(x_{1}),...,f(x_{N}))</script> jointly follows a Gaussian, with average <script type="math/tex">Œº(x)</script> and covariance <script type="math/tex">‚àë(x)</script> given by <script type="math/tex">‚àë_{i,j}=k(x_{i},x_{j})</script>, where $k$ is a kernel function. The key idea is that if <script type="math/tex">x_{i}</script> and <script type="math/tex">x_{j}</script> the kernel considers them to be similar, then we expect the output of the function at those points to be similar as well.</p>

<p>Just as for <script type="math/tex">Œº(x)</script> we can use any real function, for <script type="math/tex">k(x_{i},x_{j})</script> it must be fulfilled that for any set of elements, the resulting matrix is valid for a multivariable Gaussian distribution (semi-definitive positive), which are the same conditions as for <em>kernels</em>, so any kernel function can be used as a covariance function.</p>

<h2 id="software-used">Software used</h2>

<p>In order to carry out the present project, the programming language <em>Python</em> has been used, in its version 3.7. Similarly, the development environment used is <em>Pycharm</em>, from the software company JetBrains. Among the different Python packages in which the Gaussian process algorithm is implemented, in our case we will use <strong>GPflow</strong>. GPflow is a package for the construction of Gaussian process models in python, using TensorFlow to execute the calculations, which allows a faster execution than the rest of packages, because it can make use of GPU.</p>

<p>To implement the models used in this project, the object <strong>VGP</strong>, present in the <em>models</em> package, has been used. This implementation of the Variational Gaussian Process (VGP) approximates the subsequent distribution to a multivariate Gaussian. On these VGP models, we have defined the probability distribution that we will use. In our case, as it is a binary classification problem, we will use a Bernouilli distribution. Finally, according to the formal requirements established for this work, two different types of kernel are used for the Gaussian process: one linear (Linear) and another Gaussian (RBF), both within the <em>kernels</em> package. For both <em>kernels</em> the size of the <em>input_dim</em> variable has been modified to set it to the number of variables to consider of our data set.</p>

<p>In addition, the other software packages that have been used for the implementation of this practice have been:</p>

<ul>
  <li><strong>matplotlib</strong>: To carry out the visualizations of the graphics to be shown in the results (ROC curves, confusion matrices‚Ä¶).</li>
  <li><strong>Sklearn</strong>: Both to carry out pre-processing tasks on the data and to calculate metrics to evaluate the classification made by the generated models.</li>
  <li><strong>numpy</strong>: To carry out calculations on matrices in a simpler and more efficient way.</li>
</ul>

<h2 id="experimental-results">Experimental results</h2>
<p>The results obtained for the cross validation of Gaussian process models are shown below, first with the linear kernel and then with the Gaussian.</p>

<h3 id="linear-kernel">Linear Kernel</h3>
<p>After cross validation on the data set, using Gaussian processes with linear kernel, we have obtained a series of metrics, which are presented below.</p>

<h5 id="roc-curve-and-precision-sensitivity-curve">ROC curve and precision-sensitivity curve</h5>
<p>It presents both the ROC curves obtained for each of the models generated in the different divisions of the data in the cross validation, as well as the precision and sensitivity curves.</p>

<p><strong>ROC curves</strong></p>

<p class="text-center">
  <img src="/assets/img/2019-03-21-gp-cancer/Linear_ROC.png" width="90%" title="ROC curves" />
</p>

<p><strong>Precision/Recall curves</strong></p>

<p class="text-center">
  <img src="/assets/img/2019-03-21-gp-cancer/Linear_prec_sen.png" width="90%" title="Precision/Recall curves" />
</p>

<p>** Matrices de confusi√≥n **</p>

<p>Del mismo modo, a continuaci√≥n se exponen las matrices de confusi√≥n correspondientes a cada uno de los modelos generados en la validaci√≥n cruzada.
<img src="Results/Lineal_CM.png" alt="alt text" title="Figura 3: Matrices de confusi√≥n de la validaci√≥n cruzada de modelos con kernel lineal" /></p>

<h4 id="m√©tricas-por-fold">M√©tricas por fold</h4>
<p>Del mismo modo, se exponen las m√©tricas concretas calculadas a partir de la matriz de confusi√≥n:</p>

<table>
  <thead>
    <tr>
      <th>Fold</th>
      <th>Accuracy</th>
      <th>Specificity</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.719844</td>
      <td>0.645320</td>
      <td>1.000000</td>
      <td>0.428571</td>
      <td>0.600000</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.510638</td>
      <td>0.342857</td>
      <td>1.000000</td>
      <td>0.342857</td>
      <td>0.510638</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.752896</td>
      <td>0.689320</td>
      <td>1.000000</td>
      <td>0.452991</td>
      <td>0.623529</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.804878</td>
      <td>0.765306</td>
      <td>0.960000</td>
      <td>0.510638</td>
      <td>0.666667</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.708955</td>
      <td>0.633166</td>
      <td>0.927536</td>
      <td>0.467153</td>
      <td>0.621359</td>
    </tr>
  </tbody>
</table>

<p>Tabla 1: M√©tricas de clasificaci√≥n para folds de modelos con n√∫cleo lineal</p>

<h4 id="comentario-de-los-resultados-para-kernel-lineal">Comentario de los resultados para kernel lineal</h4>
<p>Tras haber obtenido cada uno de los gr√°ficos y m√©tricas anteriormente expuestos, cabe decir que en t√©rminos generales, el n√∫cleo Lineal tiene un comportamiento un tanto irregular. En primer lugar, se ha de decir que la bondad de la clasificaci√≥n no es siempre buena, tal y como se observan en los resultados anteriores. As√≠, se observa como por ejemplo en el fold 2, la exactitud del clasificador est√° en torno al 50%, con una especificidad cercana al 35%, pero sin embargo con una sensibilidad del 100%. As√≠, en este caso el clasificador parece ser robusto a falsos negativos, penalizando en gran medida los falsos positivos, que en el caso de un problema tan cr√≠tico como el de la detecci√≥n de c√°ncer, resultar√≠a ser una buena caracter√≠stica. Sin embargo, en este fold en concreto, parece como si el modelo no fuera capaz de clasificar la clase negativa. El resto de folds mantienen un comportamiento similar con respecto a la sensibilidad, si bien en el 4 y en el 5 ya se avistan ciertos falsos negativos. Sin embargo, es en la capacidad predictiva de la clase negativa donde el resto de folds tienen un rendimiento mucho mejor que el 2.</p>

<h3 id="kernel-gaussiano">Kernel Gaussiano</h3>
<p>Del mismo modo que se ha hecho para el kernel lineal, se han obtenido una serie de m√©tricas y gr√°ficos sobre los resultados conseguidos con el proceso gaussiano de kernel gaussiano, que a continuaci√≥n se exponen.</p>

<h3 id="curva-roc-y-curva-precisi√≥n-sensibilidad">Curva ROC y curva precisi√≥n-sensibilidad</h3>
<p>Curvas ROC                     |  Curvas Precisi√≥n/Sensibilidad
:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äì:|:‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-:
<img src="Results/Gaussian_ROC.png" alt="alt text" title="Figura 4: Curvas ROC GP con n√∫cleo gaussiano" />  |  <img src="Results/Gaussian_prec_sen.png" alt="alt text" title="Figura5: Curvas precisi√≥n/sensibilidad GP con n√∫cleo gaussiano" /></p>

<h4 id="matrices-de-confusi√≥n">Matrices de confusi√≥n</h4>
<p>Del mismo modo, a continuaci√≥n se exponen las matrices de confusi√≥n correspondientes a cada uno de los modelos generados en la validaci√≥n cruzada.
<img src="Results/Gaussian_CM.png" alt="alt text" title="Figura 6: Matrices de confusi√≥n de la validaci√≥n cruzada de modelos con kernel gaussiano" /></p>

<h4 id="m√©tricas-por-fold-1">M√©tricas por fold</h4>
<p>Del mismo modo, se exponen las m√©tricas concretas calculadas a partir de la matriz de confusi√≥n:</p>

<table>
  <thead>
    <tr>
      <th>Fold</th>
      <th>Accuracy</th>
      <th>Specificity</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.871595</td>
      <td>0.916256</td>
      <td>0.703704</td>
      <td>0.690909</td>
      <td>0.697248</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.748227</td>
      <td>0.752381</td>
      <td>0.736111</td>
      <td>0.504762</td>
      <td>0.598870</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.938224</td>
      <td>0.980583</td>
      <td>0.773585</td>
      <td>0.911111</td>
      <td>0.836735</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.894309</td>
      <td>0.903061</td>
      <td>0.860000</td>
      <td>0.693548</td>
      <td>0.767857</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.932836</td>
      <td>0.949749</td>
      <td>0.884058</td>
      <td>0.859155</td>
      <td>0.871429</td>
    </tr>
  </tbody>
</table>

<p>Tabla 2: M√©tricas de clasificaci√≥n para folds de modelos con n√∫cleo gaussiano</p>

<h4 id="comentario-de-los-resultados-para-el-kernel-gaussiano">Comentario de los resultados para el kernel gaussiano</h4>
<p>En t√©rminos generales, estos modelos con n√∫cleo gaussiano clasifican mejor que los obtenidos con n√∫cleo lineal ya que su exactitud (Accuracy) as√≠ lo muestra. Sin embargo, al tratarse de un problema altamente desbalanceado, tenemos que considerar otras medidas que nos dejen entrever la medida en la que nuestro clasificador es √∫til para la resoluci√≥n de nuestro problema. As√≠, podemos observar como la clasificaci√≥n de la clase negativa es en general buena para todos los modelos generados en los distintos folds, siendo la especificidad de los modelos mucho mejor que las obtenidas en los modelos con n√∫cleo lineal. Otro aspecto fundamental en un problema de estas caracter√≠sticas es la sensibilidad de nuestros modelos ya que tal y como se puede apreciar, en estos modelos con n√∫cleo gaussiano, esta baja considerablemente con respecto a los resultados obtenidos con el n√∫cleo lineal. Esto resulta un aspecto significativo y muy negativo, pues sobre sujetos que est√°n enfermos, nuestros clasificadores los dar√≠an como sanos, teniendo en este caso un coste muy elevado la clasificaci√≥n err√≥nea. As√≠ y aunque tanto la especificidad y precisi√≥n de estos modelos resulta mejor que la de los obtenidos con n√∫cleo lineal, la baja sensibilidad nos podr√≠a hacer considerar la opci√≥n de incluso descartar estos modelos.</p>

<h2 id="c√≥mo-se-clasificar√≠a-un-nuevo-dato">¬øC√≥mo se clasificar√≠a un nuevo dato?</h2>
<p>Tras haber entrenado los modelos cuyos resultados se han mostrado anteriormente, nos surge la duda de c√≥mo deber√≠amos clasificar un nuevo dato que llega a nuestro sistema. As√≠, en este ep√≠grafe se propone un procedimiento para llevar a cabo esta tarea, cuyo proceso se describe en las siguientes fases:</p>

<ol>
  <li>En primer lugar, se ha de obtener sobre una imagen nueva, los descriptores del mismo modo que se obtuvieron para los datos de entrenamiento utilizados para entrenar nuestros modelos, de forma que para esta nueva imagen se generen 10 caracter√≠sticas, relativas a cada uno de los descriptores.</li>
  <li>A continuaci√≥n, se ha de llevar a cabo la normalizaci√≥n (centrado y escalado) de este nuevo dato para que pueda ser comparable a los datos con los que se ha entrenado el modelo. Por ello, ha de obtenerse el Z-Score de cada una de las caracter√≠sticas del nuevo dato con la media y desviaci√≥n t√≠pica obtenida para cada una de las variables cuando se realiz√≥ el procedo de normalizado de datos.</li>
  <li>Como los datos ya son comparables con los usados para el entrenamiento, se puede llevar a cabo la clasificaci√≥n del nuevo dato. Para ello y como tras el entrenamiento de los procesos gaussianos resultaron 20 modelos distintos, hemos de buscar un m√©todo para aunar de alg√∫n modo todos y establecer un criterio de selecci√≥n de la clase predicha. Para ello, procedemos del siguiente modo:
    <ol>
      <li>Efectuamos la clasificaci√≥n de nuestro nuevo dato sobre los 20 modelos generados, lo que resulta en un vector de 20 probabilidades respecto a la clasificaci√≥n binaria. Estos datos nos dicen para cada uno de los modelos la probabilidad de que el nuevo dato se corresponda con la clase positiva.</li>
      <li>Sobre esas probabilidades establecemos un threshold, por defecto de 0.5 para poder discernir a partir de qu√© valor de la probabilidad obtenida por cada uno de los modelos, diferenciamos entre la clase positiva y la negativa. Con ello, obtenemos un vector de 20 elementos, teniendo cada uno de estos el valor de la clase que se corresponde con la probabilidad determinada por el respectivo modelo.</li>
      <li>La selecci√≥n de la clase a considerar como la predicha por el sistema se realizar√° eligiendo aquella que m√°s veces aparece en el vector de clases de salida de cada uno de nuestros clasificadores. As√≠, nuestra propuesta de multiclasificador resultar√≠a del consenso o votaci√≥n de los clasificadores procesos gaussianos parciales.</li>
    </ol>
  </li>
</ol>

<h2 id="dise√±o-de-experimento-adicional">Dise√±o de experimento adicional</h2>
<p>En esta pr√°ctica hemos utilizado bagging para balancear las clases. <strong>Tenemos 1014 y 298 ejemplos sanos y cancer√≠genos, respectivamente</strong>. Una duda que se plantea es la b√∫squeda de otra alternativa para aumentar el n√∫mero de ejemplos positivos para balancear los datos. As√≠ en este trabajo adem√°s de la alternativa de bagging, se propone utilizar SMOTE o algunas de las implementaciones similares a este algoritmo, como por ejemplo ADASYN como m√©todo para equilibrar el n√∫mero de muestras de la clase positiva al de clase negativa. As√≠, la responsabilidad del balanceo de las clases pasa del algoritmo de partici√≥n de datos y generaci√≥n de modelos (en nuestro caso bagging), que simula para cada modelo una situaci√≥n de igualdad de datos de cada clase, a ahora residir en el preprocesamiento, que haciendo uso de la distribuci√≥n de los datos observados generar√° otras muestras que se adec√∫en a las mismas caracter√≠sticas.</p>

<p>Es cierto que la generaci√≥n de datos artificiales puede tener inconvenientes, como la poca representatividad de los mismo, haciendo que estos no pertenezcan a la distribuci√≥n que subyace en el dominio de los datos reales. Por ello, una primera alternativa que se tuvo en consideraci√≥n fue llevar a cabo un undersampling, que si bien cumple el requisito fundamental de que las clases de los datos resultantes se encontrar√°n balanceadas, por contra tiene la pega de que se disminuye la cantidad de datos con la que entrenar nuestro modelo, con lo que pueden haber ciertos aspectos del dominio de nuestros datos que no queden cubiertos y nos lleve casi con total seguridad a una peor clasificaci√≥n.</p>

<p>En cuanto a los algoritmos de sampling de datos a utilizar, se propone tanto SMOTE como ADASYN. El funcionamiento de SMOTE es simple. Primero encuentra a los vecinos m√°s cercanos de la clase minoritaria para cada una de las muestras de la clase. Luego dibuja una l√≠nea entre los vecinos y genera puntos aleatorios en dichas l√≠neas. Por su parte ADASYN hace es lo mismo que SMOTE, s√≥lo que con un peque√±o cambio. Despu√©s de crear esa muestra, a√±ade peque√±os valores aleatorios a los puntos, lo que la hace m√°s realista. En otras palabras, en lugar de que toda la muestra est√© linealmente correlacionada con el padre, tienen un poco m√°s de varianza en ellos, es decir, est√°n un poco dispersos.</p>

<p>As√≠, una vez que se tiene el conjunto de datos balanceado deber√≠amos proceder a entrenar nuestro modelo. Para ello realizaremos una validaci√≥n cruzada, por ejemplo de 10-fold. Adicionalmente y si hay par√°metros que se considere que pueden influir de forma positiva en la capacidad predictiva del algoritmo, se puede realizar un Grid de par√°metros, de forma que generar√° sobre cada combinaci√≥n posible de par√°metros una validaci√≥n cruzada, permitiendo observar cual es con la que obtenemos mejores resultados.</p>

<p>Con la combinaci√≥n de par√°metros deseada, se obtendr√° un modelo final, que usar√° como datos de entrenamiento la totalidad del conjunto de datos, de forma que este modelo podr√° usarse para la clasificaci√≥n de datos de nuevas im√°genes que nos lleguen.</p>
:ET