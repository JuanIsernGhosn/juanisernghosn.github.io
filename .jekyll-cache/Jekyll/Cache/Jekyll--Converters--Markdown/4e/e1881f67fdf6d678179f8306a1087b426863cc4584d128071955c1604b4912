I"q<p>This practice is based on the use of Gaussian processes for the <strong>classification of histological images of the prostate, according to the existence or not of cancer</strong>.</p>

<p>Specifically, this project uses a data set of 1014 images from healthy tissue and 298 from carcinogenic tissue, from which 10 descriptors have been extracted. In this set of data, the folds to be used in cross validation are predetermined, so that the data are first divided according to their class and then each of them in 5 sets of similar size, each representative of a fold of cross validation.</p>

<p>To carry out the classification of the image data, the Gaussian process algorithm will be used, whose functioning will be defined in this report, prior to the presentation of the results obtained through it in the data set. Thus, one of the main challenges of the problem presented here, is the need to achieve the best possible classification through this algorithm, on a set of data that is highly unbalanced. For this reason and for each of the folds of the majority class (negative class) of the cross validation to be performed, we will take all the data of the positive class in order to balance the observations of each class in the models to be trained.</p>

<h2 id="what-is-a-gaussian-process">What is a Gaussian process?</h2>
<p>A Gaussian process consists of a (potentially infinite) collection of random variables, each of which follows a normal distribution, for which given any finite subset of the same, this follows a multivariate normal distribution.</p>

<script type="math/tex; mode=display">f(x) ∼ GP(m(x), k(x,x'))</script>

<p>This notation means that for each value <script type="math/tex">x ∈ R^n</script>, we consider the function <script type="math/tex">f(x)</script> as a random variable, that is to say, a distribution is defined on the set of real functions, being the function of average:</p>

<script type="math/tex; mode=display">m(x) := E[f(x)]</script>

<p>and the covariance function:</p>

<script type="math/tex; mode=display">k(x, x') := E[(f(x) − m(x))(f(x') − m(x'))]</script>

<p>Intuitively this means that the value of <script type="math/tex">f(x)</script> is treated as a random variable with an average of <script type="math/tex">m(x)</script> and a covariance between pairs of random variables.</p>

<p>Thus, a Gaussian process defines a previous distribution, which can be converted to a later distribution once we have seen some data. Although it may seem difficult to represent a distribution over a function, it turns out that we just need to be able to define it over the function values in a set of finite points, but arbitrary, for example <script type="math/tex">x_{1},...,x_{N}</script>. A Gaussian process assumes that <script type="math/tex">p(f(x_{1}),...,f(x_{N}))</script> jointly follows a Gaussian, with average <script type="math/tex">μ(x)</script> and covariance <script type="math/tex">∑(x)</script> given by <script type="math/tex">∑_{i,j}=k(x_{i},x_{j})</script>, where $k$ is a kernel function. The key idea is that if <script type="math/tex">x_{i}</script> and <script type="math/tex">x_{j}</script> the kernel considers them to be similar, then we expect the output of the function at those points to be similar as well.</p>

<p>Just as for <script type="math/tex">μ(x)</script> we can use any real function, for <script type="math/tex">k(x_{i},x_{j})</script> it must be fulfilled that for any set of elements, the resulting matrix is valid for a multivariable Gaussian distribution (semi-definitive positive), which are the same conditions as for <em>kernels</em>, so any kernel function can be used as a covariance function.</p>

<h2 id="software-used">Software used</h2>

<p>In order to carry out the present project, the programming language <em>Python</em> has been used, in its version 3.7. Similarly, the development environment used is <em>Pycharm</em>, from the software company JetBrains. Among the different Python packages in which the Gaussian process algorithm is implemented, in our case we will use <strong>GPflow</strong>. GPflow is a package for the construction of Gaussian process models in python, using TensorFlow to execute the calculations, which allows a faster execution than the rest of packages, because it can make use of GPU.</p>

<p>To implement the models used in this project, the object <strong>VGP</strong>, present in the <em>models</em> package, has been used. This implementation of the Variational Gaussian Process (VGP) approximates the subsequent distribution to a multivariate Gaussian. On these VGP models, we have defined the probability distribution that we will use. In our case, as it is a binary classification problem, we will use a Bernouilli distribution. Finally, according to the formal requirements established for this work, two different types of kernel are used for the Gaussian process: one linear (Linear) and another Gaussian (RBF), both within the <em>kernels</em> package. For both <em>kernels</em> the size of the <em>input_dim</em> variable has been modified to set it to the number of variables to consider of our data set.</p>

<p>In addition, the other software packages that have been used for the implementation of this practice have been:</p>

<ul>
  <li><strong>matplotlib</strong>: To carry out the visualizations of the graphics to be shown in the results (ROC curves, confusion matrices…).</li>
  <li><strong>Sklearn</strong>: Both to carry out pre-processing tasks on the data and to calculate metrics to evaluate the classification made by the generated models.</li>
  <li><strong>numpy</strong>: To carry out calculations on matrices in a simpler and more efficient way.</li>
</ul>

<h2 id="experimental-results">Experimental results</h2>
<p>The results obtained for the cross validation of Gaussian process models are shown below, first with the linear kernel and then with the Gaussian.</p>

<h3 id="linear-kernel">Linear Kernel</h3>
<p>After cross validation on the data set, using Gaussian processes with linear kernel, we have obtained a series of metrics, which are presented below.</p>

<h5 id="roc-curve-and-precision-sensitivity-curve">ROC curve and precision-sensitivity curve</h5>
<p>It presents both the ROC curves obtained for each of the models generated in the different divisions of the data in the cross validation, as well as the precision and sensitivity curves.</p>

<p><strong>ROC curves</strong></p>

<p class="text-center">
  <img src="/assets/img/2019-03-21-gp-cancer/Linear_ROC.png" width="90%" title="ROC curves" />
</p>

<p><strong>Precision/Recall curves</strong></p>

<p class="text-center">
  <img src="/assets/img/2019-03-21-gp-cancer/Linear_prec_sen.png" width="90%" title="Precision/Recall curves" />
</p>

<p><strong>Confusion Matrices</strong></p>

<p>Similarly, the confusion matrices corresponding to each of the models generated in the cross validation are set out below.</p>

<p class="text-center">
  <img src="/assets/img/2019-03-21-gp-cancer/Lineal_CM.png
" width="90%" title="Confusion Matrices" />
</p>

<h4 id="metrics-by-fold">Metrics by fold</h4>
<p>Similarly, concrete metrics calculated from the confusion matrix are presented:</p>

<p class="text-center">
<table style="border-collapse:collapse;border-spacing:0;border-color:#ccc" class="tg"><tr><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">Fold</th><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">Accuracy</th><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">Specificity</th><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">Recall</th><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">Precision</th><th style="font-family:Arial, sans-serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#f0f0f0;text-align:left;vertical-align:top">F_Score</th></tr><tr><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;font-weight:bold;text-align:left;vertical-align:top">1</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.719844</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.645320</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">1.000000</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.428571</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.600000</td></tr><tr><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;font-weight:bold;text-align:left;vertical-align:top">2</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.510638</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.342857</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">1.000000</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.342857</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.510638</td></tr><tr><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;font-weight:bold;text-align:left;vertical-align:top">3</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.752896</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.689320</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">1.000000</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.452991</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.623529</td></tr><tr><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;font-weight:bold;text-align:left;vertical-align:top">4</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.804878</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.765306</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.960000</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.510638</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.666667</td></tr><tr><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;font-weight:bold;text-align:left;vertical-align:top">5</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.708955</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.633166</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.927536</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.467153</td><td style="font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-top-width:1px;border-bottom-width:1px;border-color:#ccc;color:#333;background-color:#fff;text-align:left;vertical-align:top">0.621359</td></tr></table>
</p>

<h4 id="comentario-de-los-resultados-para-kernel-lineal">Comentario de los resultados para kernel lineal</h4>
<p>Tras haber obtenido cada uno de los gráficos y métricas anteriormente expuestos, cabe decir que en términos generales, el núcleo Lineal tiene un comportamiento un tanto irregular. En primer lugar, se ha de decir que la bondad de la clasificación no es siempre buena, tal y como se observan en los resultados anteriores. Así, se observa como por ejemplo en el fold 2, la exactitud del clasificador está en torno al 50%, con una especificidad cercana al 35%, pero sin embargo con una sensibilidad del 100%. Así, en este caso el clasificador parece ser robusto a falsos negativos, penalizando en gran medida los falsos positivos, que en el caso de un problema tan crítico como el de la detección de cáncer, resultaría ser una buena característica. Sin embargo, en este fold en concreto, parece como si el modelo no fuera capaz de clasificar la clase negativa. El resto de folds mantienen un comportamiento similar con respecto a la sensibilidad, si bien en el 4 y en el 5 ya se avistan ciertos falsos negativos. Sin embargo, es en la capacidad predictiva de la clase negativa donde el resto de folds tienen un rendimiento mucho mejor que el 2.</p>

<h3 id="kernel-gaussiano">Kernel Gaussiano</h3>
<p>Del mismo modo que se ha hecho para el kernel lineal, se han obtenido una serie de métricas y gráficos sobre los resultados conseguidos con el proceso gaussiano de kernel gaussiano, que a continuación se exponen.</p>

<h3 id="curva-roc-y-curva-precisión-sensibilidad">Curva ROC y curva precisión-sensibilidad</h3>
<p>Curvas ROC                     |  Curvas Precisión/Sensibilidad
:—————————–:|:———————————-:
<img src="Results/Gaussian_ROC.png" alt="alt text" title="Figura 4: Curvas ROC GP con núcleo gaussiano" />  |  <img src="Results/Gaussian_prec_sen.png" alt="alt text" title="Figura5: Curvas precisión/sensibilidad GP con núcleo gaussiano" /></p>

<h4 id="matrices-de-confusión">Matrices de confusión</h4>
<p>Del mismo modo, a continuación se exponen las matrices de confusión correspondientes a cada uno de los modelos generados en la validación cruzada.
<img src="Results/Gaussian_CM.png" alt="alt text" title="Figura 6: Matrices de confusión de la validación cruzada de modelos con kernel gaussiano" /></p>

<h4 id="métricas-por-fold">Métricas por fold</h4>
<p>Del mismo modo, se exponen las métricas concretas calculadas a partir de la matriz de confusión:</p>

<table>
  <thead>
    <tr>
      <th>Fold</th>
      <th>Accuracy</th>
      <th>Specificity</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F_Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.871595</td>
      <td>0.916256</td>
      <td>0.703704</td>
      <td>0.690909</td>
      <td>0.697248</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.748227</td>
      <td>0.752381</td>
      <td>0.736111</td>
      <td>0.504762</td>
      <td>0.598870</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.938224</td>
      <td>0.980583</td>
      <td>0.773585</td>
      <td>0.911111</td>
      <td>0.836735</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.894309</td>
      <td>0.903061</td>
      <td>0.860000</td>
      <td>0.693548</td>
      <td>0.767857</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.932836</td>
      <td>0.949749</td>
      <td>0.884058</td>
      <td>0.859155</td>
      <td>0.871429</td>
    </tr>
  </tbody>
</table>

<p>Tabla 2: Métricas de clasificación para folds de modelos con núcleo gaussiano</p>

<h4 id="comentario-de-los-resultados-para-el-kernel-gaussiano">Comentario de los resultados para el kernel gaussiano</h4>
<p>En términos generales, estos modelos con núcleo gaussiano clasifican mejor que los obtenidos con núcleo lineal ya que su exactitud (Accuracy) así lo muestra. Sin embargo, al tratarse de un problema altamente desbalanceado, tenemos que considerar otras medidas que nos dejen entrever la medida en la que nuestro clasificador es útil para la resolución de nuestro problema. Así, podemos observar como la clasificación de la clase negativa es en general buena para todos los modelos generados en los distintos folds, siendo la especificidad de los modelos mucho mejor que las obtenidas en los modelos con núcleo lineal. Otro aspecto fundamental en un problema de estas características es la sensibilidad de nuestros modelos ya que tal y como se puede apreciar, en estos modelos con núcleo gaussiano, esta baja considerablemente con respecto a los resultados obtenidos con el núcleo lineal. Esto resulta un aspecto significativo y muy negativo, pues sobre sujetos que están enfermos, nuestros clasificadores los darían como sanos, teniendo en este caso un coste muy elevado la clasificación errónea. Así y aunque tanto la especificidad y precisión de estos modelos resulta mejor que la de los obtenidos con núcleo lineal, la baja sensibilidad nos podría hacer considerar la opción de incluso descartar estos modelos.</p>

<h2 id="cómo-se-clasificaría-un-nuevo-dato">¿Cómo se clasificaría un nuevo dato?</h2>
<p>Tras haber entrenado los modelos cuyos resultados se han mostrado anteriormente, nos surge la duda de cómo deberíamos clasificar un nuevo dato que llega a nuestro sistema. Así, en este epígrafe se propone un procedimiento para llevar a cabo esta tarea, cuyo proceso se describe en las siguientes fases:</p>

<ol>
  <li>En primer lugar, se ha de obtener sobre una imagen nueva, los descriptores del mismo modo que se obtuvieron para los datos de entrenamiento utilizados para entrenar nuestros modelos, de forma que para esta nueva imagen se generen 10 características, relativas a cada uno de los descriptores.</li>
  <li>A continuación, se ha de llevar a cabo la normalización (centrado y escalado) de este nuevo dato para que pueda ser comparable a los datos con los que se ha entrenado el modelo. Por ello, ha de obtenerse el Z-Score de cada una de las características del nuevo dato con la media y desviación típica obtenida para cada una de las variables cuando se realizó el procedo de normalizado de datos.</li>
  <li>Como los datos ya son comparables con los usados para el entrenamiento, se puede llevar a cabo la clasificación del nuevo dato. Para ello y como tras el entrenamiento de los procesos gaussianos resultaron 20 modelos distintos, hemos de buscar un método para aunar de algún modo todos y establecer un criterio de selección de la clase predicha. Para ello, procedemos del siguiente modo:
    <ol>
      <li>Efectuamos la clasificación de nuestro nuevo dato sobre los 20 modelos generados, lo que resulta en un vector de 20 probabilidades respecto a la clasificación binaria. Estos datos nos dicen para cada uno de los modelos la probabilidad de que el nuevo dato se corresponda con la clase positiva.</li>
      <li>Sobre esas probabilidades establecemos un threshold, por defecto de 0.5 para poder discernir a partir de qué valor de la probabilidad obtenida por cada uno de los modelos, diferenciamos entre la clase positiva y la negativa. Con ello, obtenemos un vector de 20 elementos, teniendo cada uno de estos el valor de la clase que se corresponde con la probabilidad determinada por el respectivo modelo.</li>
      <li>La selección de la clase a considerar como la predicha por el sistema se realizará eligiendo aquella que más veces aparece en el vector de clases de salida de cada uno de nuestros clasificadores. Así, nuestra propuesta de multiclasificador resultaría del consenso o votación de los clasificadores procesos gaussianos parciales.</li>
    </ol>
  </li>
</ol>

<h2 id="diseño-de-experimento-adicional">Diseño de experimento adicional</h2>
<p>En esta práctica hemos utilizado bagging para balancear las clases. <strong>Tenemos 1014 y 298 ejemplos sanos y cancerígenos, respectivamente</strong>. Una duda que se plantea es la búsqueda de otra alternativa para aumentar el número de ejemplos positivos para balancear los datos. Así en este trabajo además de la alternativa de bagging, se propone utilizar SMOTE o algunas de las implementaciones similares a este algoritmo, como por ejemplo ADASYN como método para equilibrar el número de muestras de la clase positiva al de clase negativa. Así, la responsabilidad del balanceo de las clases pasa del algoritmo de partición de datos y generación de modelos (en nuestro caso bagging), que simula para cada modelo una situación de igualdad de datos de cada clase, a ahora residir en el preprocesamiento, que haciendo uso de la distribución de los datos observados generará otras muestras que se adecúen a las mismas características.</p>

<p>Es cierto que la generación de datos artificiales puede tener inconvenientes, como la poca representatividad de los mismo, haciendo que estos no pertenezcan a la distribución que subyace en el dominio de los datos reales. Por ello, una primera alternativa que se tuvo en consideración fue llevar a cabo un undersampling, que si bien cumple el requisito fundamental de que las clases de los datos resultantes se encontrarán balanceadas, por contra tiene la pega de que se disminuye la cantidad de datos con la que entrenar nuestro modelo, con lo que pueden haber ciertos aspectos del dominio de nuestros datos que no queden cubiertos y nos lleve casi con total seguridad a una peor clasificación.</p>

<p>En cuanto a los algoritmos de sampling de datos a utilizar, se propone tanto SMOTE como ADASYN. El funcionamiento de SMOTE es simple. Primero encuentra a los vecinos más cercanos de la clase minoritaria para cada una de las muestras de la clase. Luego dibuja una línea entre los vecinos y genera puntos aleatorios en dichas líneas. Por su parte ADASYN hace es lo mismo que SMOTE, sólo que con un pequeño cambio. Después de crear esa muestra, añade pequeños valores aleatorios a los puntos, lo que la hace más realista. En otras palabras, en lugar de que toda la muestra esté linealmente correlacionada con el padre, tienen un poco más de varianza en ellos, es decir, están un poco dispersos.</p>

<p>Así, una vez que se tiene el conjunto de datos balanceado deberíamos proceder a entrenar nuestro modelo. Para ello realizaremos una validación cruzada, por ejemplo de 10-fold. Adicionalmente y si hay parámetros que se considere que pueden influir de forma positiva en la capacidad predictiva del algoritmo, se puede realizar un Grid de parámetros, de forma que generará sobre cada combinación posible de parámetros una validación cruzada, permitiendo observar cual es con la que obtenemos mejores resultados.</p>

<p>Con la combinación de parámetros deseada, se obtendrá un modelo final, que usará como datos de entrenamiento la totalidad del conjunto de datos, de forma que este modelo podrá usarse para la clasificación de datos de nuevas imágenes que nos lleguen.</p>
:ET